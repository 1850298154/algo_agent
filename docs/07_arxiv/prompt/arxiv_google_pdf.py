import arxiv
import requests
import os
import re
import time

def sanitize_filename(filename):
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    return re.sub(r'[\\/*?:"<>|]', "", filename).strip()

def generate_bibtex(result):
    """æ ¹æ® arXiv result å¯¹è±¡ç”Ÿæˆ BibTeX å­—ç¬¦ä¸²"""
    short_id = result.get_short_id()
    #ä»¥æ­¤æ ¼å¼ç”Ÿæˆå¼•ç”¨key: AuthorYearTitleWord
    first_author_lastname = result.authors[0].name.split(' ')[-1].lower()
    year = result.published.year
    first_word_title = result.title.split(' ')[0].lower()
    cite_key = f"{first_author_lastname}{year}{first_word_title}"
    
    authors_str = " and ".join([a.name for a in result.authors])
    
    bibtex = f"""@misc{{{cite_key},
      title={{{result.title}}}, 
      author={{{authors_str}}},
      year={{{result.published.year}}},
      eprint={{{short_id}}},
      archivePrefix={{arXiv}},
      primaryClass={{{result.primary_category}}}
}}"""
    return bibtex

def download_papers(paper_titles, base_dir="Paper_Downloads"):
    """
    æ‰¹é‡ä¸‹è½½ PDF, LaTeX Source, BibTeX
    """
    if not os.path.exists(base_dir):
        os.makedirs(base_dir)
        
    client = arxiv.Client()

    for title in paper_titles:
        print(f"\nğŸ” æ­£åœ¨æœç´¢: {title} ...")
        
        # 1. æœç´¢è®ºæ–‡
        search = arxiv.Search(
            query=f'ti:"{title}"',
            max_results=1,
            sort_by=arxiv.SortCriterion.Relevance
        )
        
        try:
            result = next(client.results(search))
        except StopIteration:
            print(f"âŒ æœªæ‰¾åˆ°è®ºæ–‡: {title}")
            continue
        except Exception as e:
            print(f"âŒ æœç´¢å‡ºé”™: {e}")
            continue

        # æ ¡éªŒï¼šå¦‚æœæœç´¢ç»“æœæ ‡é¢˜å’Œè¾“å…¥å·®å¼‚å¤ªå¤§ï¼ˆæ¯”å¦‚æœä¸åˆ°åŒ¹é…äº†åˆ«çš„ï¼‰ï¼Œå¯ä»¥åŠ é€»è¾‘åˆ¤æ–­
        # è¿™é‡Œç›´æ¥ä¿¡ä»» arXiv çš„ç›¸å…³æ€§æ’åºç¬¬ä¸€å
        
        # å‡†å¤‡æ–‡ä»¶è·¯å¾„
        safe_title = sanitize_filename(result.title)
        # æˆªæ–­è¿‡é•¿çš„æ–‡ä»¶åé˜²æ­¢ç³»ç»ŸæŠ¥é”™
        if len(safe_title) > 150: 
            safe_title = safe_title[:150]
            
        paper_dir = os.path.join(base_dir, safe_title)
        if not os.path.exists(paper_dir):
            os.makedirs(paper_dir)
            
        print(f"   ğŸ“‚ ç›®æ ‡æ–‡ä»¶å¤¹: {paper_dir}")

        # ---------------------------
        # 2. ç”Ÿæˆå¹¶ä¿å­˜ BibTeX
        # ---------------------------
        bib_path = os.path.join(paper_dir, "citation.bib")
        with open(bib_path, "w", encoding="utf-8") as f:
            f.write(generate_bibtex(result))
        print("   âœ… [1/3] BibTeX å·²ä¿å­˜")

        # ---------------------------
        # 3. ä¸‹è½½ PDF
        # ---------------------------
        try:
            # result.download_pdf ä¼šè‡ªåŠ¨å¤„ç†æ–‡ä»¶åï¼Œä½†æˆ‘ä»¬æƒ³æŒ‡å®šè·¯å¾„
            pdf_path = os.path.join(paper_dir, f"{safe_title}.pdf")
            if not os.path.exists(pdf_path):
                result.download_pdf(dirpath=paper_dir, filename=f"{safe_title}.pdf")
                print("   âœ… [2/3] PDF å·²ä¸‹è½½")
            else:
                print("   âš ï¸ [2/3] PDF å·²å­˜åœ¨ï¼Œè·³è¿‡")
        except Exception as e:
            print(f"   âŒ PDF ä¸‹è½½å¤±è´¥: {e}")

        # ---------------------------
        # 4. ä¸‹è½½ LaTeX æºç  (Source)
        # ---------------------------
        # arXiv çš„æºç ä¸‹è½½é“¾æ¥æ ¼å¼é€šå¸¸æ˜¯ /e-print/{id}
        source_url = f"https://arxiv.org/e-print/{result.get_short_id()}"
        source_path = os.path.join(paper_dir, "source.tar.gz")
        
        if not os.path.exists(source_path):
            try:
                r = requests.get(source_url, stream=True)
                if r.status_code == 200:
                    # æ³¨æ„ï¼šå¦‚æœè¿™ç¯‡è®ºæ–‡æ²¡æœ‰ä¸Šä¼  LaTeX æºç ï¼ˆåªæœ‰PDFï¼‰ï¼Œè¿™ä¸ªé“¾æ¥ä¸‹è½½ä¸‹æ¥çš„å…¶å®æ˜¯ PDF
                    # æˆ‘ä»¬å¯ä»¥æ£€æŸ¥ Content-Typeï¼Œä½†é€šå¸¸é»˜è®¤ä¿å­˜ä¸º tar.gz
                    with open(source_path, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=1024):
                            if chunk:
                                f.write(chunk)
                    print("   âœ… [3/3] LaTeX æºç å·²ä¸‹è½½ (source.tar.gz)")
                else:
                    print(f"   âŒ LaTeX æºç ä¸‹è½½å¤±è´¥ (Status: {r.status_code})")
            except Exception as e:
                print(f"   âŒ LaTeX æºç è¯·æ±‚å‡ºé”™: {e}")
        else:
            print("   âš ï¸ [3/3] LaTeX æºç å·²å­˜åœ¨ï¼Œè·³è¿‡")
            
        # ç¤¼è²Œæ€§å»¶æ—¶ï¼Œé˜²æ­¢è¯·æ±‚è¿‡å¿«è¢«å° IP
        time.sleep(1)

# =================ä½¿ç”¨ç¤ºä¾‹=================
if __name__ == "__main__":
    # åœ¨è¿™é‡Œå¡«å…¥ä½ æƒ³ä¸‹è½½çš„è®ºæ–‡æ ‡é¢˜åˆ—è¡¨
    papers_to_download = [
        "Attention Is All You Need",
        "Deep Residual Learning for Image Recognition",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        # "è¿™é‡Œå¯ä»¥æ”¾ä»»æ„ä¸å­˜åœ¨çš„è®ºæ–‡æµ‹è¯•æŠ¥é”™"
    ]

    download_papers(papers_to_download, base_dir="./My_Arxiv_Papers")