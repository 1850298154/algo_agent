import streamlit as st
import arxiv
import pandas as pd
import os
import re
import glob
import plotly.express as px
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# ================= å…¨å±€é…ç½® =================
DOWNLOAD_DIR = "Paper_Library"

# é¢„å®šä¹‰çš„æŸ¥è¯¢è¯­å¥åˆ—è¡¨ (è¿™é‡Œåªæ”¾ä¸€éƒ¨åˆ†ç¤ºä¾‹ï¼Œå®é™…è¯·æŠŠæ‰€æœ‰åˆ—è¡¨æ”¾è¿›æ¥)
PREDEFINED_QUERIES = {
    "æ ¸å¿ƒä¸»é¢˜": [
        'ti:"multi-agent path planning" AND ti:"deadlock resolution"',
        'abs:"distributed multi-agent" AND abs:"deadlock breaking"',
    ],
    "LLMä¸AI Agent": [
        'all:"Large Language Model" AND all:"multi-agent path planning"',
        'ti:"LLM" AND ti:"task allocation" AND ti:"robot"',
    ],
    "è¿ç­¹ä¼˜åŒ–": [
        'ti:"column generation" AND ti:"vehicle routing" AND ti:"UAV"',
        'all:"mixed integer linear programming" AND all:"heterogeneous UAV"',
    ],
    # ... ä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šåˆ†ç±»
}

# å±•å¹³æŸ¥è¯¢ç”¨äºä¸‹æ‹‰èœå•
FLAT_QUERIES = []
for category, q_list in PREDEFINED_QUERIES.items():
    for q in q_list:
        FLAT_QUERIES.append(f"[{category}] {q}")

# ================= åŠŸèƒ½å‡½æ•° =================

def parse_bib_file(bib_path):
    """ç®€å•çš„ BibTeX è§£æå™¨"""
    with open(bib_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    data = {}
    # æå– title
    title_match = re.search(r'title=\{(.*?)\}', content, re.DOTALL)
    data['title'] = title_match.group(1) if title_match else "Unknown Title"
    
    # æå– year
    year_match = re.search(r'year=\{(.*?)\}', content)
    data['year'] = int(year_match.group(1)) if year_match else 0
    
    # æå– authors
    author_match = re.search(r'author=\{(.*?)\}', content)
    if author_match:
        data['authors'] = [a.strip() for a in author_match.group(1).split(' and ')]
        data['primary_author'] = data['authors'][0]
    else:
        data['authors'] = []
        data['primary_author'] = "Unknown"
        
    # æå– primaryClass
    class_match = re.search(r'primaryClass=\{(.*?)\}', content)
    data['category'] = class_match.group(1) if class_match else "Uncategorized"
    
    return data

def load_local_library():
    """æ‰«ææœ¬åœ°ä¸‹è½½ç›®å½•"""
    papers = []
    if not os.path.exists(DOWNLOAD_DIR):
        return pd.DataFrame()
        
    # éå†æ‰€æœ‰ citation.bib
    bib_files = glob.glob(os.path.join(DOWNLOAD_DIR, "*", "citation.bib"))
    
    for bib in bib_files:
        try:
            meta = parse_bib_file(bib)
            meta['path'] = os.path.dirname(bib) # æ–‡ä»¶å¤¹è·¯å¾„
            papers.append(meta)
        except Exception as e:
            continue
            
    return pd.DataFrame(papers)

# ================= Streamlit UI =================

st.set_page_config(page_title="ArXiv Paper Manager", layout="wide")

st.title("ğŸ“š ArXiv Multi-Agent & UAV Research Hub")

tab1, tab2 = st.tabs(["ğŸ” Search Explorer", "ğŸ“Š Local Library Analytics"])

# ---------- TAB 1: å®æ—¶æœç´¢ ----------
with tab1:
    st.markdown("### é€‰æ‹©æŸ¥è¯¢è¯­å¥è¿›è¡Œå®æ—¶æ£€ç´¢")
    
    # é€‰æ‹©æ¡†
    selected_query_raw = st.selectbox("é€‰æ‹©é¢„å®šä¹‰æŸ¥è¯¢:", FLAT_QUERIES)
    
    # æå–å®é™…çš„ query å­—ç¬¦ä¸² (å»æ‰ [Category] å‰ç¼€)
    query_str = selected_query_raw.split("] ", 1)[1] if "] " in selected_query_raw else selected_query_raw
    
    # å…è®¸ç”¨æˆ·ä¿®æ”¹
    user_query = st.text_input("ç¼–è¾‘æŸ¥è¯¢è¯­å¥ (æ”¯æŒ arXiv è¯­æ³•):", value=query_str)
    
    max_res = st.slider("æœ€å¤§è¿”å›æ•°é‡", 5, 50, 10)
    
    if st.button("å¼€å§‹æœç´¢ (Search arXiv)", type="primary"):
        st.info(f"æ­£åœ¨æœç´¢: `{user_query}` ...")
        
        client = arxiv.Client()
        search = arxiv.Search(
            query=user_query,
            max_results=max_res,
            sort_by=arxiv.SortCriterion.Relevance
        )
        
        results = list(client.results(search))
        
        st.success(f"æ‰¾åˆ° {len(results)} ç¯‡ç›¸å…³è®ºæ–‡")
        
        for p in results:
            with st.expander(f"{p.title} ({p.published.year})"):
                st.markdown(f"**Authors:** {', '.join([a.name for a in p.authors])}")
                st.markdown(f"**Category:** `{p.primary_category}` | **Published:** {p.published.date()}")
                st.markdown(f"**Abstract:**")
                st.caption(p.summary)
                st.markdown(f"[PDF Link]({p.pdf_url}) | [ArXiv Page]({p.entry_id})")

# ---------- TAB 2: æœ¬åœ°åº“åˆ†æ ----------
with tab2:
    st.markdown(f"### æœ¬åœ°åº“åˆ†æ (ç›®å½•: `{DOWNLOAD_DIR}`) mac/linux path")
    
    df = load_local_library()
    
    if df.empty:
        st.warning("âš ï¸ æœ¬åœ°å°šæœªä¸‹è½½ä»»ä½•è®ºæ–‡ï¼Œæˆ–è€…è·¯å¾„ä¸æ­£ç¡®ã€‚è¯·å…ˆè¿è¡Œä¸‹è½½è„šæœ¬ã€‚")
    else:
        st.markdown(f"**æ€»è®¡ä¸‹è½½è®ºæ–‡:** `{len(df)}` ç¯‡")
        
        # 1. ä¾§è¾¹æ è¿‡æ»¤å™¨
        st.sidebar.header("Filter Options")
        
        # å¹´ä»½è¿‡æ»¤
        min_year, max_year = int(df['year'].min()), int(df['year'].max())
        years = st.sidebar.slider("é€‰æ‹©å¹´ä»½èŒƒå›´", min_year, max_year, (min_year, max_year))
        
        # å­¦ç§‘è¿‡æ»¤
        all_cats = df['category'].unique()
        selected_cats = st.sidebar.multiselect("é€‰æ‹©å­¦ç§‘åˆ†ç±»", all_cats, default=all_cats)
        
        # åº”ç”¨è¿‡æ»¤
        mask = (df['year'].between(years[0], years[1])) & (df['category'].isin(selected_cats))
        filtered_df = df[mask]
        
        st.divider()
        
        # 2. å›¾è¡¨å±•ç¤ºåŒº
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“… è®ºæ–‡å¹´ä»½åˆ†å¸ƒ")
            year_counts = filtered_df['year'].value_counts().sort_index()
            fig_year = px.bar(year_counts, x=year_counts.index, y=year_counts.values, labels={'x':'Year', 'y':'Count'})
            st.plotly_chart(fig_year, use_container_width=True)
            
        with col2:
            st.subheader("ğŸ·ï¸ å­¦ç§‘åˆ†ç±»åˆ†å¸ƒ")
            cat_counts = filtered_df['category'].value_counts()
            fig_cat = px.pie(values=cat_counts.values, names=cat_counts.index, hole=0.4)
            st.plotly_chart(fig_cat, use_container_width=True)
            
        # 3. ä½œè€…åˆ†æ (Word Cloud)
        st.subheader("â˜ï¸ ä½œè€…å½±å“åŠ›è¯äº‘")
        all_authors = [author for authors_list in filtered_df['authors'] for author in authors_list]
        if all_authors:
            author_text = " ".join([a.replace(" ", "_") for a in all_authors]) # å°†å§“åè¿èµ·æ¥é˜²æ­¢è¢«æ‹†åˆ†
            wordcloud = WordCloud(width=800, height=300, background_color='white').generate(author_text)
            
            fig, ax = plt.subplots()
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)
            
        # 4. è®ºæ–‡åˆ—è¡¨å±•ç¤º
        st.subheader("ğŸ“„ è¯¦ç»†åˆ—è¡¨")
        st.dataframe(
            filtered_df[['year', 'title', 'primary_author', 'category']],
            use_container_width=True,
            hide_index=True
        )