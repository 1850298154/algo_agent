import os
import asyncio
import aiofiles
from src.retrieval.arXiv.utils.logger import logger
from src.retrieval.arXiv.utils.helpers import sanitize_filename, generate_bibtex

class DownloadService:
    def __init__(self, network_client, download_dir):
        self.client = network_client
        self.base_dir = download_dir
        self.processed_ids = set()

    async def _download_file(self, url, path, desc):
        """å†…éƒ¨ä¸‹è½½å®ç°ï¼Œä½¿ç”¨æµå¼ä¼ è¾“"""
        if os.path.exists(path):
            logger.info(f"â­ï¸  [Skip] {desc} exists.")
            return

        async with self.client.get_stream(url, context_info=desc) as response:
            if response:
                logger.info(f"ğŸš€ [Downloading] {desc}")
                try:
                    async with aiofiles.open(path, 'wb') as f:
                        async for chunk in response.content.iter_chunked(64 * 1024):
                            await f.write(chunk)
                    logger.info(f"âœ… [Done] {desc}")
                except Exception as e:
                    logger.error(f"âŒ [Write Error] {desc}: {e}")
                    if os.path.exists(path):
                        os.remove(path) # åˆ é™¤ä¸å®Œæ•´æ–‡ä»¶

    async def process_paper(self, paper):
        """å¤„ç†å•ç¯‡è®ºæ–‡çš„æ‰€æœ‰ä¸‹è½½ä»»åŠ¡"""
        paper_id = paper.get_short_id()
        
        if paper_id in self.processed_ids:
            return
        self.processed_ids.add(paper_id)

        clean_title = sanitize_filename(paper.title)
        short_title = clean_title[:40] + "..."
        paper_dir = os.path.join(self.base_dir, clean_title)
        
        if not os.path.exists(paper_dir):
            os.makedirs(paper_dir)

        # 1. ä¿å­˜ BibTeX (æœ¬åœ°IOï¼Œä¸æ¶ˆè€—ä»¤ç‰Œ)
        bib_path = os.path.join(paper_dir, "citation.bib")
        if not os.path.exists(bib_path):
            with open(bib_path, "w", encoding="utf-8") as f:
                f.write(generate_bibtex(paper))

        # 2. å¹¶å‘ä¸‹è½½ PDF å’Œ Source (éƒ½ä¼šæ¶ˆè€—ä»¤ç‰Œ)
        pdf_url = paper.pdf_url
        source_url = f"https://export.arxiv.org/e-print/{paper_id}"
        
        pdf_path = os.path.join(paper_dir, f"{clean_title}.pdf")
        source_path = os.path.join(paper_dir, "source.tar.gz")

        task_pdf = self._download_file(pdf_url, pdf_path, f"PDF [{paper_id}]")
        task_src = self._download_file(source_url, source_path, f"SRC [{paper_id}]")

        await asyncio.gather(task_pdf, task_src)